Анализ двух подходов к решению задачи на Kaggle
1. Первая работа (базовая модель — 0.92 на публичном лидерборде)
Код и подход:

используется простой пайплайн (Pipeline) с предобработкой (ColumnTransformer) и XGBClassifier;

предобработка включает:

масштабирование числовых признаков (StandardScaler);

one-hot-кодирование категориальных признаков (OneHotEncoder);

модель обучается на всём датасете после кросс-валидации (5 фолдов, метрика — F1);

предсказания делаются через predict_proba, берётся вероятность класса 1;

минимум инженерных признаков — используются исходные данные.

Почему сработало:

простота побеждает переобучение: базовая модель не «запоминает» шум в данных, хорошо обобщает;

нет гиперпараметрической оптимизации — это парадоксально может давать лучший результат, так как модель не «подточена» под кросс-валидацию и не переобучается;

быстрая сходимость XGBoost с дефолтными параметрами часто даёт хороший старт в соревнованиях;

избежание утечки данных: минимум трансформаций → меньше шансов случайно использовать тестовую статистику.

2. Вторая работа (оптимизированные XGBoost и LightGBM — ~0.79 на лидерборде)
Код и подход:

Feature Engineering: добавлены сложные признаки (отношения доходов к кредиту, «индекс риска» и др.);

Оптимизация гиперпараметров с Optuna для XGBoost и LightGBM (10 итераций, поиск по сетке параметров);

Кросс-валидация с F1-метрикой для оценки параметров;

Две модели (XGBoost и LightGBM) с индивидуальной оптимизацией;

Финальные предсказания — жёсткие классы (не вероятности).
Почему результат хуже:

Переобучение на кросс-валидации:

Optuna максимизирует F1 на кросс-валидации, но эта метрика может не совпадать с публичным лидербордом (разные выборки);

модели «заучивают» паттерны в обучающей выборке, не обобщаются на тест.

Сложные признаки могут навредить:

искусственные признаки (например, income_to_loan) могут вводить шум или коррелировать с шумом;

стратификация классов или временные зависимости не учтены — признаки могут «утекать» из теста в обучение.

Проблемы с предсказаниями:

используются жёсткие классы (predict), а не вероятности (predict_proba) — это критично для ROC-AUC/F1 на лидерборде;

вероятностные предсказания сглаживают крайние значения и дают более стабильный результат.

Разрыв между CV и тестом:

F1 на кросс-валидации не всегда коррелирует с публичным скорром (разные распределения классов, утечки данных);

LightGBM и XGBoost чувствительны к балансу классов — если валидация не отражает тест, результат проседает.

Локальные оптимумы Optuna:

10 итераций — мало для надёжного поиска;

возможно, попали в локальный максимум F1, который не переносится на тест.
